{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as web\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num:2987 Start/Stop 338/599\n",
      "338 WTM\n",
      "339 WLAB\n",
      "340 WECFF\n",
      "341 WHR\n",
      "342 WFCF\n",
      "343 WHLKY\n",
      "344 WHLKF\n",
      "345 WPM\n",
      "346 WY\n",
      "347 WEYS\n",
      "348 WEX\n",
      "349 WHG\n",
      "350 WWR\n",
      "351 WTSHF\n",
      "352 WPRT\n",
      "353 WEBNF\n",
      "354 WBK\n",
      "355 WMTN\n",
      "356 WLK\n",
      "357 WKGFF\n",
      "358 WAB\n",
      "359 WTCRF\n",
      "360 WTRNF\n",
      "361 WNEB\n",
      "362 WTLC\n",
      "363 WEEEF\n",
      "364 WDC\n",
      "365 WRN\n",
      "366 GFY\n",
      "367 WEA\n",
      "368 MNP\n",
      "369 MHF\n",
      "370 MTT\n",
      "371 DMO\n",
      "372 MMU\n",
      "373 IGI\n",
      "374 PAI\n",
      "375 SBI\n",
      "376 WIW\n",
      "377 WIA\n",
      "378 HYI\n",
      "379 HIO\n",
      "380 HIX\n",
      "381 EHI\n",
      "382 GDO\n",
      "383 EMD\n",
      "384 TLI\n",
      "385 WAL\n",
      "386 WSTL\n",
      "387 WEGYF\n",
      "388 WABC\n",
      "389 WEDXF\n",
      "390 WSSH\n",
      "391 WST\n",
      "392 WHYRF\n",
      "393 WFTBF\n",
      "394 WCHNF\n",
      "395 WTBA\n",
      "396 WFAFY\n",
      "397 WFAFF\n",
      "398 WDOFF\n",
      "399 WCC\n",
      "400 WSBC\n",
      "401 WERN\n",
      "402 WNDLF\n",
      "403 WELL\n",
      "404 WTKN\n",
      "405 ERH\n",
      "406 ERC\n",
      "407 EAD\n",
      "408 EOD\n",
      "409 WFC\n",
      "410 WMK\n",
      "411 WEIGF\n",
      "412 WQTEF\n",
      "413 WRI\n",
      "414 WEICY\n",
      "415 WEICF\n",
      "416 BUDZ\n",
      "417 WCIG\n",
      "418 WECT\n",
      "419 WEC\n",
      "420 WBS\n",
      "421 WBSI\n",
      "422 WEBC\n",
      "423 WEBB\n",
      "424 WHSI\n",
      "425 WMLLF\n",
      "426 WDFC\n",
      "427 WCFB\n",
      "428 WSTG\n",
      "429 WAYN\n",
      "430 WXMN\n",
      "431 WFTSF\n",
      "432 WTS\n",
      "433 WSO\n",
      "434 WSBF\n",
      "435 WAT\n",
      "436 BIBLF\n",
      "437 WM\n",
      "438 WCN\n",
      "439 WASH\n",
      "440 WRE\n",
      "441 WAFD\n",
      "442 WSRUF\n",
      "443 WMT\n",
      "444 WLBMF\n",
      "445 WKLN\n",
      "446 WD\n",
      "447 WBA\n",
      "448 WMMVY\n",
      "449 WMMVF\n",
      "450 WAKE\n",
      "451 WJXFF\n",
      "452 WDR\n",
      "453 WACLY\n",
      "454 WKRCF\n",
      "455 WNC\n",
      "456 GWW\n",
      "457 WPC\n",
      "458 WTI\n",
      "459 WTCG\n",
      "460 GRA\n",
      "461 VYST\n",
      "462 VUZI\n",
      "463 VULMF\n",
      "464 VMC\n",
      "465 VULC\n",
      "466 VSEC\n",
      "467 VSBN\n",
      "468 VIH\n",
      "469 PPR\n",
      "470 IRR\n",
      "471 IID\n",
      "472 IDE\n",
      "473 IGD\n",
      "474 IGA\n",
      "475 IAE\n",
      "476 VOXX\n",
      "477 VNO\n",
      "478 VG\n",
      "479 VOLVF\n",
      "480 VOLAF\n",
      "481 VOLT\n",
      "482 VLKPF\n",
      "483 VLKAF\n",
      "484 VPLM\n",
      "485 VLPNY\n",
      "486 VLPNF\n",
      "487 VODPF\n",
      "488 VOD\n",
      "489 VMW\n",
      "490 VVUSQ\n",
      "491 RDGL\n",
      "492 VCII\n",
      "493 VIVE\n",
      "494 VIVEF\n",
      "495 VIVK\n",
      "496 VODG\n",
      "497 VTSYF\n",
      "498 VC\n",
      "499 VGZ\n",
      "500 VKSC\n",
      "501 VSTCQ\n",
      "502 VGMIF\n",
      "503 VPG\n",
      "504 VSH\n",
      "505 V\n",
      "506 VRTU\n",
      "507 VRTS\n",
      "508 VHC\n",
      "509 VABK\n",
      "510 VBHLF\n",
      "511 VIRC\n",
      "512 VOQP\n",
      "513 NDYN\n",
      "514 VINS\n",
      "515 VCISY\n",
      "516 VCISF\n",
      "517 VLGEA\n",
      "518 VBFC\n",
      "519 VKIN\n",
      "520 GNHAF\n",
      "521 VIAAY\n",
      "522 VNRFY\n",
      "523 NIHK\n",
      "524 VIDE\n",
      "525 VRCFF\n",
      "526 VNCKF\n",
      "527 VITFF\n",
      "528 VICR\n",
      "529 VCON\n",
      "530 VIAV\n",
      "531 VTRS\n",
      "532 VGREF\n",
      "533 VSAT\n",
      "534 VVI\n",
      "535 VFC\n",
      "536 VTNA\n",
      "537 VRTA\n",
      "538 VWSYF\n",
      "539 VWDRY\n",
      "540 VERU\n",
      "541 VCSY\n",
      "542 VRTX\n",
      "543 VTNR\n",
      "544 VET\n",
      "545 VZ\n",
      "546 VRTC\n",
      "547 VRSK\n",
      "548 VRSN\n",
      "549 YNGFF\n",
      "550 VRNT\n",
      "551 VRME\n",
      "552 VSMR\n",
      "553 VCEL\n",
      "554 AMHPF\n",
      "555 OEZVY\n",
      "556 OEZVF\n",
      "557 VRA\n",
      "558 VEON\n",
      "559 VEOEY\n",
      "560 VEOEF\n",
      "561 SNSFF\n",
      "562 VPTDF\n",
      "563 VTR\n",
      "564 VNTA\n",
      "565 OXFCF\n",
      "566 VPGI\n",
      "567 VECO\n",
      "568 VEDL\n",
      "569 VETTF\n",
      "570 VGR\n",
      "571 VNWTF\n",
      "572 VBIV\n",
      "573 VXRT\n",
      "574 VASO\n",
      "575 VSMD\n",
      "576 VAR\n",
      "577 VGLDF\n",
      "578 VNDA\n",
      "579 VNCI\n",
      "580 APAFF\n",
      "581 VPGLF\n",
      "582 VALU\n",
      "583 KVLQF\n",
      "584 MKRMF\n",
      "585 INRLF\n",
      "586 VMI\n",
      "587 VLOUF\n",
      "588 VLLX\n",
      "589 VLY\n",
      "590 VLDI\n",
      "591 PSRU\n",
      "592 VHI\n",
      "593 VLO\n",
      "594 VLEEY\n",
      "595 VLEEF\n",
      "596 VALE\n",
      "597 MTN\n",
      "598 VCEX\n",
      "599 EGY\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "BOT = {\"NUM\":1, \"MAX\":5}\n",
    "START_YR = \"2009\"\n",
    "YRS_MIN = 10\n",
    "FORCE_UPDATE = False\n",
    "REPASS = False\n",
    "LAST_POS = True\n",
    "STOCK_LIST_DIR = \"stock_list\"\n",
    "DIR = {\n",
    "    \"RAW\": \"data/raw\",\n",
    "    \"YRS\": \"data/yearly\",\n",
    "    \"under_min\": \"data/under_min\"\n",
    "}\n",
    "\n",
    "# if BOT['NUM']>1:\n",
    "#     tickers = pd.read_csv(r'{}.csv'.format(STOCK_LIST_DIR), engine='python')\n",
    "#     tickers.to_csv(r'{}{}.csv'.format(STOCK_LIST_DIR, BOT['NUM']))\n",
    "#     STOCK_LIST_DIR = \"stock_list{}\".format(BOT['NUM'])\n",
    "\n",
    "def set_col(df, c_name, c_type=\"str\", tmp_i=\"False\", v=np.nan):\n",
    "    if not (c_name in df.columns):\n",
    "        if c_type == \"str\":\n",
    "            df[c_name] = \"\"\n",
    "            df[c_name] = df[c_name].astype(str)\n",
    "        else:\n",
    "            df[c_name] = np.nan\n",
    "    if not tmp_i == \"False\":\n",
    "        if c_type == \"str\":\n",
    "            try:\n",
    "                df.at[tmp_i, c_name] = \"\"\n",
    "            except:\n",
    "                df[c_name] = \"\"\n",
    "                \n",
    "        df.at[tmp_i, c_name] = v\n",
    "        \n",
    "\n",
    "try:\n",
    "    tickers = pd.read_csv(r'{}.csv'.format(STOCK_LIST_DIR), engine='python')\n",
    "    tickers = tickers.loc[:, ~tickers.columns.str.contains('^Unnamed')]\n",
    "except:\n",
    "    pass\n",
    "    tickers = pd.DataFrame()\n",
    "    \n",
    "t_len = 0\n",
    "t_len_fixed = 0\n",
    "START_LIST_NUM = 0\n",
    "END_LIST_NUM = 0\n",
    "if BOT['MAX'] > 0:\n",
    "    t_len = len(tickers.index)\n",
    "    t_len_fixed = t_len+[n for n in list(range(BOT['MAX'])) if (t_len+n)%BOT['MAX']==0][0]\n",
    "    START_LIST_NUM = int((t_len_fixed/BOT['MAX'])*(BOT['NUM']-1))\n",
    "    if BOT['MAX'] != BOT['NUM']:\n",
    "        END_LIST_NUM = int((t_len_fixed/BOT['MAX'])*BOT['NUM'])\n",
    "START_LIST_NUM = 337\n",
    "print(\"Num:{} Start/Stop {}/{}\".format(t_len, START_LIST_NUM+1, END_LIST_NUM+1 if END_LIST_NUM>0 else t_len_fixed))\n",
    "        \n",
    "set_col(tickers, 'symbol')\n",
    "set_col(tickers, 'company')\n",
    "set_col(tickers, 'price', \"int\")\n",
    "set_col(tickers, 'ignore')\n",
    "set_col(tickers, 'start_yr')\n",
    "set_col(tickers, 'ignore_error')\n",
    "# set_col(tickers, 'adj_up_start_schedule')\n",
    "# set_col(tickers, 'adj_up_end_schedule')\n",
    "\n",
    "if tickers.empty:\n",
    "    tickers.to_csv(r'{}.csv'.format(STOCK_LIST_DIR))\n",
    "\n",
    "\n",
    "for i, row in tickers.iterrows():\n",
    "    if START_LIST_NUM>0 and i<START_LIST_NUM:\n",
    "        continue\n",
    "    if END_LIST_NUM>0 and END_LIST_NUM>START_LIST_NUM and i>END_LIST_NUM:\n",
    "        break\n",
    "    SYMBOL = row[\"symbol\"]\n",
    "#     SYMBOL = \"PG\"\n",
    "    \n",
    "    try:        \n",
    "        current_stock = pd.read_csv(r'{}/{}_{}.csv'.format(DIR['RAW'], SYMBOL, \"history\"), index_col=['Date'] , parse_dates=['Date'])\n",
    "        tickers.at[i, \"ignore\"] = False\n",
    "    except:\n",
    "        current_stock = \"\"\n",
    "        \n",
    "    print(i+1, SYMBOL)\n",
    "    if (pd.notnull(row['ignore']) and row['ignore'] and not REPASS):\n",
    "        print(\"--Ignore: {}\".format(row['ignore'] and not REPASS))\n",
    "        continue\n",
    "    if FORCE_UPDATE or not str(current_stock):\n",
    "        print(\"--get data\")\n",
    "        try:\n",
    "#             sleep(15)\n",
    "            current_stock = web.DataReader(SYMBOL, data_source=\"yahoo\", start=START_YR) \n",
    "            set_col(tickers, \"ignore\",\"str\", i, False)\n",
    "        except Exception as e:\n",
    "            set_col(tickers, \"ignore\",\"str\", i, True)\n",
    "            set_col(tickers, \"ignore_error\",\"str\", i, e)\n",
    "            print(\"---Error: {}\".format(e))\n",
    "            tickers.to_csv(r'{}.csv'.format(STOCK_LIST_DIR))\n",
    "            continue\n",
    "    \n",
    "        \n",
    "\n",
    "    tickers.at[i, \"price\"] = current_stock.tail(1)[\"Close\"][0]\n",
    "    tickers.at[i, \"ignore\"] = skip = current_stock.tail(1).index[0].year-current_stock.head(1).index[0].year < YRS_MIN\n",
    "    tickers.at[i, \"start_yr\"] = current_stock.head(1).index[0].year\n",
    "#     print(\"--Skip: {}\".format(skip))\n",
    "    if skip:\n",
    "        current_stock.to_csv(r'{}/{}_{}.csv'.format(DIR[\"under_min\"], current_stock.head(1).index[0].year, SYMBOL))\n",
    "        tickers.to_csv(r'{}.csv'.format(STOCK_LIST_DIR))\n",
    "        continue\n",
    "    else:\n",
    "#         if REPASS or not os.path.exists(r'{}/{}_{}.csv'.format(DIR['RAW'], SYMBOL, \"history\")):\n",
    "        current_stock.to_csv(r'{}/{}_{}.csv'.format(DIR['RAW'], SYMBOL, \"history\"))\n",
    "\n",
    "#     if REPASS or not os.path.exists(r'{}/{}_yrs_adj_data.csv'.format(DIR['YRS'], SYMBOL)) or not os.path.exists(r'{}/{}_yrs_close_data.csv'.format(YRS_DIR, SYMBOL)):\n",
    "    yearly_adj_df = pd.DataFrame()\n",
    "    yearly_df = pd.DataFrame()\n",
    "    for j, row2 in current_stock.iterrows():\n",
    "        yearly_adj_df.at[\"{:02d}-{:02d}\".format(j.month, j.day), j.year] = row2[\"Adj Close\"]\n",
    "        yearly_df.at[\"{:02d}-{:02d}\".format(j.month, j.day), j.year] = row2[\"Close\"]\n",
    "\n",
    "    yearly_adj_df.sort_index(inplace=True)\n",
    "    yearly_df.sort_index(inplace=True)\n",
    "#     else:\n",
    "#         yearly_adj_df = pd.read_csv(r'{}/{}_yrs_adj_data.csv'.format(DIR['YRS'], SYMBOL), parse_dates=True, index_col=['Unnamed: 0'], engine='python')\n",
    "#         yearly_df = pd.read_csv(r'{}/{}_yrs_close_data.csv'.format(DIR['YRS'], SYMBOL), parse_dates=True, index_col=['Unnamed: 0'], engine='python')\n",
    "        \n",
    "    r_adj_df_list = {}\n",
    "    r_c_df_list = {}\n",
    "    r_pc_df_list = {}\n",
    "    d_range = list(range(61))[0::15][1:][::-1]\n",
    "    for r in d_range:\n",
    "        r_adj_df_list[r] = pd.DataFrame()\n",
    "        r_c_df_list[r] = pd.DataFrame()\n",
    "        r_pc_df_list[r] = pd.DataFrame()\n",
    "        for j, row2 in yearly_df.iterrows():\n",
    "            adj_d_ups = adj_d_downs = c_d_ups = c_d_downs = 0\n",
    "            for yr in yearly_df.columns:\n",
    "                d = pd.to_datetime('{}-{}'.format(yr, j), format=\"%Y-%m-%d\", dayfirst=True, errors='coerce')\n",
    "                r_adj_df_list[r].at[j, yr] = r_c_df_list[r].at[j, yr] = r_pc_df_list[r].at[j, yr] = 0\n",
    "                if not pd.isnull(d):\n",
    "                    f = d + datetime.timedelta(days=r)\n",
    "                    tmp_r_df = current_stock.loc['{}-{:02d}-{:02d}'.format(d.year, d.month, d.day):'{}-{:02d}-{:02d}'.format(f.year, f.month, f.day)]\n",
    "\n",
    "                    if not tmp_r_df.empty:\n",
    "                        adj_first_range_num = tmp_r_df.head(3)[\"Adj Close\"].dropna().head(1)[0]\n",
    "                        c_first_range_num = tmp_r_df.head(3)[\"Close\"].dropna().head(1)[0]              \n",
    "                        adj_last_range_num = tmp_r_df.tail(3)[\"Adj Close\"].dropna().head(1)[0]\n",
    "                        c_last_range_num = tmp_r_df.tail(3)[\"Close\"].dropna().head(1)[0]\n",
    "\n",
    "                        r_adj_df_list[r].at[j, yr] = adj_last_range_num - adj_first_range_num\n",
    "                        r_c_df_list[r].at[j, yr] = c_last_range_num - c_first_range_num\n",
    "                        r_pc_df_list[r].at[j, yr] = ((c_last_range_num - c_first_range_num)/c_last_range_num)*100\n",
    "                        if (adj_last_range_num - adj_first_range_num)>0:\n",
    "                            adj_d_ups=adj_d_ups+1\n",
    "                        else:\n",
    "                            adj_d_downs=adj_d_downs+1\n",
    "\n",
    "                        if (c_last_range_num - c_first_range_num)>0:\n",
    "                            c_d_ups=c_d_ups+1\n",
    "                        else:\n",
    "                            c_d_downs=c_d_downs+1\n",
    "                            \n",
    "            set_col(r_adj_df_list[r], \"ups\", \"int\", j, adj_d_ups)\n",
    "            set_col(r_c_df_list[r], \"ups\", \"int\", j, c_d_ups)\n",
    "            set_col(r_pc_df_list[r], \"ups\", \"int\", j, c_d_ups)\n",
    "            set_col(r_adj_df_list[r], \"downs\", \"int\", j, adj_d_downs)\n",
    "            set_col(r_c_df_list[r], \"downs\", \"int\", j, c_d_downs)\n",
    "            set_col(r_pc_df_list[r], \"downs\", \"int\", j, c_d_downs)\n",
    "            \n",
    "            set_col(tickers, 'adj_up_start_schedule_r_{}'.format(r))\n",
    "            set_col(tickers, 'adj_up_end_schedule_r_{}'.format(r))\n",
    "            set_col(tickers, \"adj_ups_r_{}\".format(r), \"int\", i, adj_d_ups)\n",
    "            set_col(tickers, \"adj_downs_r_{}\".format(r), \"int\", i, adj_d_downs)\n",
    "            set_col(tickers, \"close_ups_r_{}\".format(r), \"int\", i, c_d_ups)\n",
    "            set_col(tickers, \"close_downs_r_{}\".format(r), \"int\", i, c_d_downs)\n",
    "            set_col(tickers, \"close_downs_r_{}\".format(r), \"int\", i, c_d_downs)\n",
    "            \n",
    "            set_col(r_adj_df_list[r], \"end_day_sum\",\"str\", j, '{:02d}-{:02d}'.format(f.month, f.day))\n",
    "            set_col(r_c_df_list[r], \"end_day_sum\",\"str\", j, '{:02d}-{:02d}'.format(f.month, f.day))\n",
    "        \n",
    "        r_adj_df_list[r]['avg'] = r_adj_df_list[r].loc[:, ~r_adj_df_list[r].columns.str.contains('^ups|^downs|^avg|^end_day_sum', na=False)].mean(axis=1)\n",
    "        r_c_df_list[r]['avg'] = r_c_df_list[r].loc[:, ~r_c_df_list[r].columns.str.contains('^ups|^downs|^avg|^end_day_sum', na=False)].mean(axis=1)\n",
    "        r_pc_df_list[r]['avg'] = r_pc_df_list[r].loc[:, ~r_pc_df_list[r].columns.str.contains('^ups|^downs|^avg|^end_day_sum', na=False)].mean(axis=1)\n",
    "\n",
    "        range_dir = \"data/r_{}\".format(r)\n",
    "        r_adj_dir = r'{}/{}_r{}_adj_data.csv'.format(range_dir, SYMBOL, r)\n",
    "        r_c_dir = r'{}/{}_r{}_c_data.csv'.format(range_dir, SYMBOL, r)\n",
    "        r_pc_dir = r'{}/{}_r{}_pc_data.csv'.format(range_dir, SYMBOL, r)\n",
    "#         if not os.path.exists(range_dir):\n",
    "#             os.mkdir(range_dir)\n",
    "        r_adj_df_list[r].sort_index(inplace=True)\n",
    "        r_adj_df_list[r].to_csv(r_adj_dir)\n",
    "        r_c_df_list[r].sort_index(inplace=True)\n",
    "        r_c_df_list[r].to_csv(r_c_dir)\n",
    "        r_pc_df_list[r].sort_index(inplace=True)\n",
    "        r_pc_df_list[r].to_csv(r_pc_dir)\n",
    "\n",
    "        set_col(tickers, \"adj_up_start_schedule_r_{}\".format(r),\"str\", i, r_adj_df_list[r].sort_values(['ups', 'avg'], ascending=[False, False]).head(1).index[0])\n",
    "        set_col(tickers, \"adj_up_end_schedule_r_{}\".format(r),\"str\", i, r_adj_df_list[r].sort_values(['ups', 'avg'], ascending=[False, False]).head(1)[\"end_day_sum\"][0])\n",
    "        set_col(tickers, \"close_up_start_schedule_r_{}\".format(r),\"str\", i, r_c_df_list[r].sort_values(['ups', 'avg'], ascending=[False, False]).head(1).index[0])\n",
    "        set_col(tickers, \"close_up_end_schedule_r_{}\".format(r),\"str\", i, r_c_df_list[r].sort_values(['ups', 'avg'], ascending=[False, False]).head(1)[\"end_day_sum\"][0])\n",
    "        set_col(tickers, \"close_up_percent_avg_r_{}\".format(r),\"int\", i, r_pc_df_list[r].sort_values(['ups', 'avg'], ascending=[False, False]).head(1)[\"avg\"][0])\n",
    "    \n",
    "#     if REPASS or not os.path.exists(r'{}/{}_yrs_adj_data.csv'.format(DIR['YRS'], SYMBOL)):\n",
    "    yearly_adj_df.to_csv(r'{}/{}_yrs_adj_data.csv'.format(DIR['YRS'], SYMBOL))\n",
    "#     if REPASS or not os.path.exists(r'{}/{}_yrs_close_data.csv'.format(DIR['YRS'], SYMBOL)):\n",
    "    yearly_df.to_csv(r'{}/{}_yrs_close_data.csv'.format(DIR['YRS'], SYMBOL))\n",
    "    tickers.to_csv(r'{}.csv'.format(STOCK_LIST_DIR))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
